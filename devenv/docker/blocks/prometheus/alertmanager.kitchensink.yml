# Alertmanager Kitchen Sink Configuration
# This configuration demonstrates all major Alertmanager features for testing

global:
  # Global settings that apply to all receivers unless overridden
  resolve_timeout: 5m

  # HTTP configuration
  http_config:
    follow_redirects: true
    enable_http2: true

  # SMTP configuration
  smtp_from: 'alertmanager@example.com'
  smtp_smarthost: 'smtp.example.com:587'
  smtp_hello: 'alertmanager.example.com'
  smtp_auth_username: 'alertmanager@example.com'
  smtp_auth_password: 'smtp-password'
  smtp_require_tls: true

  # Slack API URL
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'

  # PagerDuty API URL
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

  # Opsgenie API settings
  opsgenie_api_key: 'opsgenie-api-key'
  opsgenie_api_url: 'https://api.opsgenie.com/'

  # VictorOps API settings
  victorops_api_key: 'victorops-api-key'
  victorops_api_url: 'https://alert.victorops.com/integrations/generic/20131114/alert/'

  # WeChat API settings
  wechat_api_url: 'https://qyapi.weixin.qq.com/cgi-bin/'
  wechat_api_secret: 'wechat-secret'
  wechat_api_corp_id: 'wechat-corp-id'

# Templates for notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route tree for alert routing
route:
  # Default receiver for alerts
  receiver: 'default-receiver'

  # Grouping configuration
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h

  # Child routes with matching and routing logic
  routes:
    # Critical alerts route to PagerDuty
    - match:
        severity: critical
      receiver: 'pagerduty-critical'
      group_wait: 10s
      repeat_interval: 5m
      continue: true # Continue matching other routes

    # Database alerts
    - match_re:
        service: ^(mysql|postgres|mongodb)$
      receiver: 'database-team'
      group_by: ['alertname', 'instance']
      routes:
        # Critical database alerts
        - match:
            severity: critical
          receiver: 'database-oncall'

    # Application alerts
    - matchers:
        - alertname =~ ".*Error.*|.*Exception.*"
      receiver: 'app-team-slack'
      group_by: ['alertname', 'namespace', 'pod']

    # Infrastructure alerts
    - match:
        team: infrastructure
      receiver: 'infra-team'
      routes:
        # Disk space warnings
        - match:
            alertname: DiskSpaceLow
          receiver: 'infra-disk-alerts'
          repeat_interval: 4h

        # Network alerts
        - match_re:
            alertname: ^(NetworkDown|HighNetworkLatency)$
          receiver: 'network-team'

    # Security alerts
    - match:
        category: security
      receiver: 'security-team'
      group_wait: 0s
      group_interval: 5m
      repeat_interval: 30m

    # Development environment alerts (muted during business hours)
    - match:
        environment: development
      receiver: 'dev-team'
      repeat_interval: 24h
      mute_time_intervals:
        - weeknights
        - weekends

    # Alerts with specific labels
    - matchers:
        - namespace = "production"
        - severity =~ "warning|critical"
      receiver: 'production-alerts'

    # Heartbeat/watchdog alerts
    - match:
        alertname: Watchdog
      receiver: 'watchdog'
      repeat_interval: 5m
      group_interval: 1m

# Time intervals for muting alerts
mute_time_intervals:
  - name: weeknights
    time_intervals:
      - times:
          - start_time: '00:00'
            end_time: '08:00'
        weekdays: ['monday:friday']
      - times:
          - start_time: '20:00'
            end_time: '24:00'
        weekdays: ['monday:friday']

  - name: weekends
    time_intervals:
      - weekdays: ['saturday', 'sunday']

  - name: business-hours
    time_intervals:
      - times:
          - start_time: '09:00'
            end_time: '17:00'
        weekdays: ['monday:friday']

  - name: holidays
    time_intervals:
      - days_of_month: ['25']
        months: ['december']
      - days_of_month: ['1']
        months: ['january']

# Inhibition rules (suppress alerts based on other alerts)
inhibit_rules:
  # Inhibit warning if critical is firing
  - source_match:
      severity: critical
    target_match:
      severity: warning
    equal: ['alertname', 'cluster', 'service']

  # Inhibit instance alerts if node is down
  - source_matchers:
      - alertname = NodeDown
    target_matchers:
      - alertname =~ ".*"
    equal: ['instance']

  # Inhibit all alerts from a specific namespace if maintenance
  - source_match:
      alertname: MaintenanceMode
    target_match_re:
      namespace: '.*'
    equal: ['namespace']

  # Inhibit dependent service alerts
  - source_match:
      alertname: DatabaseDown
    target_match:
      alertname: ApplicationError
    equal: ['cluster']

# Receiver configurations
receivers:
  # Default catch-all receiver
  - name: 'default-receiver'
    webhook_configs:
      - url: 'http://localhost:5001/default'
        send_resolved: true

  # Email receiver
  - name: 'email-team'
    email_configs:
      - to: 'team@example.com'
        from: 'alertmanager@example.com'
        smarthost: 'smtp.example.com:587'
        auth_username: 'alertmanager@example.com'
        auth_password: 'smtp-password'
        headers:
          Subject: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.alertname }}'
        html: '{{ template "email.default.html" . }}'
        text: '{{ template "email.default.text" . }}'
        require_tls: true
        send_resolved: true

  # Slack receivers
  - name: 'app-team-slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/APP/WEBHOOK'
        channel: '#app-alerts'
        username: 'Alertmanager'
        icon_emoji: ':fire:'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
        send_resolved: true
        actions:
          - type: button
            text: 'Runbook :notebook:'
            url: '{{ (index .Alerts 0).Annotations.runbook_url }}'
          - type: button
            text: 'Dashboard :grafana:'
            url: '{{ (index .Alerts 0).Annotations.dashboard_url }}'
        fields:
          - title: 'Severity'
            value: '{{ .CommonLabels.severity }}'
            short: true
          - title: 'Environment'
            value: '{{ .CommonLabels.environment }}'
            short: true

  # PagerDuty receiver
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - routing_key: 'your-pagerduty-integration-key'
        description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
        severity: '{{ .CommonLabels.severity }}'
        details:
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'
          group_labels: '{{ .GroupLabels }}'
          common_labels: '{{ .CommonLabels }}'
          common_annotations: '{{ .CommonAnnotations }}'
        links:
          - href: '{{ (index .Alerts 0).Annotations.runbook_url }}'
            text: 'Runbook'
          - href: '{{ (index .Alerts 0).Annotations.dashboard_url }}'
            text: 'Dashboard'
        send_resolved: true

  # Opsgenie receiver
  - name: 'opsgenie-team'
    opsgenie_configs:
      - api_key: 'opsgenie-api-key'
        api_url: 'https://api.opsgenie.com/'
        message: '{{ .GroupLabels.alertname }}'
        description: '{{ .CommonAnnotations.description }}'
        priority: '{{ if eq .CommonLabels.severity "critical" }}P1{{ else if eq .CommonLabels.severity "warning" }}P3{{ else }}P5{{ end }}'
        tags: 'alertmanager,{{ .CommonLabels.cluster }},{{ .CommonLabels.service }}'
        note: 'Alert from Prometheus Alertmanager'
        responders:
          - name: 'oncall-team'
            type: 'team'
        details:
          environment: '{{ .CommonLabels.environment }}'
          cluster: '{{ .CommonLabels.cluster }}'
        send_resolved: true

  # VictorOps receiver
  - name: 'victorops-team'
    victorops_configs:
      - api_key: 'victorops-api-key'
        routing_key: 'database-team'
        message_type: '{{ if eq .Status "firing" }}{{ if eq .CommonLabels.severity "critical" }}CRITICAL{{ else }}WARNING{{ end }}{{ else }}RECOVERY{{ end }}'
        entity_display_name: '{{ .GroupLabels.alertname }}'
        state_message: '{{ .CommonAnnotations.summary }}'
        monitoring_tool: 'Prometheus'
        send_resolved: true

  # Webhook receivers with different auth methods
  - name: 'webhook-service'
    webhook_configs:
      # Webhook with basic auth
      - url: 'http://webhook-basic-auth:8080/alerts'
        send_resolved: true
        http_config:
          basic_auth:
            username: 'webhook-user'
            password: 'webhook-password'
          tls_config:
            insecure_skip_verify: false
        max_alerts: 0 # 0 means no limit
      # Webhook with bearer token
      - url: 'http://webhook-bearer:8080/alerts'
        send_resolved: true
        http_config:
          bearer_token: 'optional-bearer-token'
          tls_config:
            insecure_skip_verify: false
        max_alerts: 0

  # WeChat receiver
  - name: 'wechat-team'
    wechat_configs:
      - corp_id: 'wechat-corp-id'
        api_secret: 'wechat-api-secret'
        to_user: '@all'
        agent_id: '1000001'
        message: '{{ template "wechat.default.message" . }}'
        send_resolved: true

  # Pushover receiver
  - name: 'pushover-mobile'
    pushover_configs:
      - user_key: 'pushover-user-key'
        token: 'pushover-app-token'
        title: '{{ .GroupLabels.alertname }}'
        message: '{{ .CommonAnnotations.summary }}'
        priority: '{{ if eq .CommonLabels.severity "critical" }}2{{ else }}0{{ end }}'
        retry: 5m
        expire: 1h
        url: '{{ (index .Alerts 0).Annotations.dashboard_url }}'
        url_title: 'View Dashboard'
        send_resolved: true

  # SNS receiver (AWS)
  - name: 'sns-aws'
    sns_configs:
      - topic_arn: 'arn:aws:sns:us-east-1:123456789012:alertmanager-topic'
        subject: '{{ .GroupLabels.alertname }}'
        message: '{{ .CommonAnnotations.description }}'
        attributes:
          severity: '{{ .CommonLabels.severity }}'
          environment: '{{ .CommonLabels.environment }}'
        send_resolved: true

  # Telegram receiver
  - name: 'telegram-chat'
    telegram_configs:
      - bot_token: 'telegram-bot-token'
        chat_id: -123456789
        message: '{{ template "telegram.default.message" . }}'
        parse_mode: 'HTML'
        disable_notifications: false
        send_resolved: true

  # Discord receiver
  - name: 'discord-channel'
    discord_configs:
      - webhook_url: 'https://discord.com/api/webhooks/YOUR/WEBHOOK/URL'
        title: '{{ .GroupLabels.alertname }}'
        message: '{{ .CommonAnnotations.description }}'
        send_resolved: true

  # Microsoft Teams receiver
  - name: 'teams-channel'
    msteams_configs:
      - webhook_url: 'https://outlook.office.com/webhook/YOUR/WEBHOOK/URL'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ .CommonAnnotations.description }}'
        send_resolved: true

  # Multiple receivers combined
  - name: 'database-team'
    email_configs:
      - to: 'database-team@example.com'
        send_resolved: true
    slack_configs:
      - channel: '#database-alerts'
        send_resolved: true
    webhook_configs:
      - url: 'http://ticketing-system:8080/database-alerts'
        send_resolved: true

  - name: 'database-oncall'
    pagerduty_configs:
      - routing_key: 'database-oncall-key'
        severity: 'critical'
        send_resolved: true
    opsgenie_configs:
      - api_key: 'database-oncall-key'
        priority: 'P1'
        send_resolved: true

  - name: 'infra-team'
    slack_configs:
      - channel: '#infrastructure'
        send_resolved: true

  - name: 'infra-disk-alerts'
    email_configs:
      - to: 'infra-team@example.com'
        headers:
          Subject: 'Disk Space Alert: {{ .GroupLabels.instance }}'
        send_resolved: true

  - name: 'network-team'
    slack_configs:
      - channel: '#network-alerts'
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
        send_resolved: true

  - name: 'security-team'
    email_configs:
      - to: 'security@example.com'
        headers:
          Subject: 'SECURITY ALERT: {{ .GroupLabels.alertname }}'
        send_resolved: true
    pagerduty_configs:
      - routing_key: 'security-oncall-key'
        severity: 'critical'
        send_resolved: true

  - name: 'dev-team'
    slack_configs:
      - channel: '#dev-alerts'
        send_resolved: true

  - name: 'production-alerts'
    slack_configs:
      - channel: '#production'
        send_resolved: true
    email_configs:
      - to: 'production-team@example.com'
        send_resolved: true

  - name: 'watchdog'
    webhook_configs:
      - url: 'http://watchdog-monitor:8080/heartbeat'
        send_resolved: false
